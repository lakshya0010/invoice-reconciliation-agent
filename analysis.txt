OCR and document extraction tend to fail when invoices are messy, inconsistent, or poorly scanned. Common problems include low-resolution scans, rotated pages, stamps or signatures overlapping text, and invoices that mix tables with free-flowing text. Even when PDFs are digitally generated, text extraction can break if the document embeds text as images or uses unusual encodings. These failures usually donâ€™t look dramatic; instead, they cause missing fields, partial line items, or subtle numeric errors.

The system is designed to handle these failures without collapsing. The document intelligence agent first tries native PDF text extraction and only falls back to OCR when no usable text is found, which avoids introducing OCR noise unnecessarily. The LLM is then used to interpret whatever text is available, rather than relying on fixed templates or coordinates. Downstream agents never assume the extracted data is perfect. The matching agent uses fuzzy similarity instead of exact identifiers, and the resolution agent treats uncertainty as a signal to slow down rather than automate. If confidence is low, the system recommends review instead of approval, which mirrors how real financial teams operate.

Improving accuracy from around 70 percent to 95 percent would require adding stronger signals rather than just refining prompts. One improvement would be running multiple OCR passes with different preprocessing techniques such as deskewing, contrast enhancement, and resolution scaling, then selecting results based on confidence. Another major improvement would be splitting extraction into smaller tasks. For example, line items, totals, and supplier metadata could be extracted independently, allowing the system to retry only the uncertain parts. Accuracy would also improve by validating extracted numbers against each other, such as recomputing totals from line items and checking for inconsistencies. Finally, adapting the system to the pharmaceutical domain using a small set of real invoices would significantly boost performance, since consistent terminology and layouts repeat across suppliers.

Validating this system at a scale of ten thousand invoices per day would rely on automation and monitoring rather than manual checks. A representative validation dataset would be created to measure accuracy across different invoice types. Each agent already produces confidence scores and explanations, which makes it easy to track where and why errors occur. In production, a small percentage of invoices would be sampled daily for human review to ensure thresholds remain calibrated. Key metrics would focus on match accuracy, discrepancy precision, and escalation rates rather than maximizing automation. Because the system is designed to fail conservatively by routing uncertain cases to review, it can safely operate at high volume without risking silent financial mistakes.